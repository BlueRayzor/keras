{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Deep Learning Project.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BlueRayzor/keras/blob/master/Deep_Learning_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oD3z50iq9oFw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "11b24fd4-41ab-4cf8-833e-bcc54b718da2"
      },
      "source": [
        "# Import libraries\n",
        "#!pip install opencv-python\n",
        "import os,cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras import backend as K\n",
        "K.common.image_dim_ordering()\n",
        "#from keras.layers import Merge\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import LSTM\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
        "from keras.optimizers import SGD,RMSprop,adam\n",
        "import glob"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ap2WOTSJ-pBo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "8e771983-b5a3-4e00-8f82-c98abea4d1d8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRA8tyPU9oF-",
        "colab_type": "text"
      },
      "source": [
        "# Data Reading and Labeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6U3x1qw9oGA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "78e09bd4-4c61-490b-8c61-9e4dac9c5649"
      },
      "source": [
        "PATH = os.getcwd()\n",
        "# Define data path\n",
        "data_path = '/content/gdrive/My Drive/Deep_Learning/Course/Project/OCT_Dataset'\n",
        " \n",
        "data_dir_list = os.listdir(data_path)\n",
        "#print(data_dir_list)\n",
        "\n",
        "img_rows=128\n",
        "img_cols=128\n",
        "num_channel=1\n",
        "num_epoch=2\n",
        "no_images=0\n",
        "\n",
        "for dataset in data_dir_list:\n",
        "    img_list = os.listdir(data_path + '/' + dataset)\n",
        "    no_images = no_images+len(img_list)\n",
        "    \n",
        "\n",
        "# Define the number of classes\n",
        "labels = np.ones((no_images,),dtype='int64')\n",
        "num_classes = 3\n",
        "label_index=0\n",
        "img_data_list=[]\n",
        "img=0\n",
        "\n",
        "for dataset in data_dir_list:\n",
        "    img_list=os.listdir(data_path+'/'+ dataset)\n",
        "    print ('Loaded the images of dataset-'+'{}\\n'.format(dataset))\n",
        "    for img in img_list:\n",
        "        input_img=cv2.imread(data_path + '/'+ dataset + '/'+ img)\n",
        "        input_img=cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)\n",
        "        input_img_resize=cv2.resize(input_img,(128,128))\n",
        "        img_data_list.append(input_img_resize)\n",
        "        if dataset[0]==  'A':\n",
        "            labels[label_index]=  0\n",
        "            #print(dataset[0])\n",
        "        if dataset[0] == 'D':\n",
        "            labels[label_index] = 1\n",
        "            #print(dataset[0])\n",
        "        if dataset[0] == 'N':\n",
        "            labels[label_index] = 2\n",
        "        label_index = label_index+1\n",
        "            #print(dataset[0])\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded the images of dataset-AMD14\n",
            "\n",
            "Loaded the images of dataset-AMD12\n",
            "\n",
            "Loaded the images of dataset-AMD2\n",
            "\n",
            "Loaded the images of dataset-AMD10\n",
            "\n",
            "Loaded the images of dataset-AMD3\n",
            "\n",
            "Loaded the images of dataset-AMD13\n",
            "\n",
            "Loaded the images of dataset-AMD15\n",
            "\n",
            "Loaded the images of dataset-AMD4\n",
            "\n",
            "Loaded the images of dataset-AMD1\n",
            "\n",
            "Loaded the images of dataset-AMD11\n",
            "\n",
            "Loaded the images of dataset-DME12\n",
            "\n",
            "Loaded the images of dataset-AMD5\n",
            "\n",
            "Loaded the images of dataset-DME11\n",
            "\n",
            "Loaded the images of dataset-DME10\n",
            "\n",
            "Loaded the images of dataset-AMD8\n",
            "\n",
            "Loaded the images of dataset-AMD7\n",
            "\n",
            "Loaded the images of dataset-DME13\n",
            "\n",
            "Loaded the images of dataset-AMD6\n",
            "\n",
            "Loaded the images of dataset-AMD9\n",
            "\n",
            "Loaded the images of dataset-DME1\n",
            "\n",
            "Loaded the images of dataset-DME2\n",
            "\n",
            "Loaded the images of dataset-DME14\n",
            "\n",
            "Loaded the images of dataset-DME15\n",
            "\n",
            "Loaded the images of dataset-DME6\n",
            "\n",
            "Loaded the images of dataset-DME8\n",
            "\n",
            "Loaded the images of dataset-DME5\n",
            "\n",
            "Loaded the images of dataset-DME4\n",
            "\n",
            "Loaded the images of dataset-DME9\n",
            "\n",
            "Loaded the images of dataset-DME3\n",
            "\n",
            "Loaded the images of dataset-DME7\n",
            "\n",
            "Loaded the images of dataset-NORMAL1\n",
            "\n",
            "Loaded the images of dataset-NORMAL11\n",
            "\n",
            "Loaded the images of dataset-NORMAL14\n",
            "\n",
            "Loaded the images of dataset-NORMAL4\n",
            "\n",
            "Loaded the images of dataset-NORMAL10\n",
            "\n",
            "Loaded the images of dataset-NORMAL15\n",
            "\n",
            "Loaded the images of dataset-NORMAL12\n",
            "\n",
            "Loaded the images of dataset-NORMAL2\n",
            "\n",
            "Loaded the images of dataset-NORMAL3\n",
            "\n",
            "Loaded the images of dataset-NORMAL13\n",
            "\n",
            "Loaded the images of dataset-NORMAL8\n",
            "\n",
            "Loaded the images of dataset-NORMAL5\n",
            "\n",
            "Loaded the images of dataset-NORMAL9\n",
            "\n",
            "Loaded the images of dataset-NORMAL7\n",
            "\n",
            "Loaded the images of dataset-NORMAL6\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0n8A3Tp9oGM",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "MzVDQMpJ9oGO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 832
        },
        "outputId": "a0c65917-b37a-4024-ab41-1c568ce27292"
      },
      "source": [
        "img_data = np.array(img_data_list)\n",
        "img_data = img_data.astype('float32')\n",
        "img_data /= 255\n",
        "print (img_data.shape)\n",
        "\n",
        "\n",
        "# Using 'th' for the image_dim_ordering we get accuracy >=0.99 . \n",
        "# Using 'tf' for the dim order I get accuracy >= 0.9 but on more epochs\n",
        "if num_channel==1:\n",
        "    if K.common.image_dim_ordering()=='th':\n",
        "        img_data= np.expand_dims(img_data, axis=1)\n",
        "        #print (img_data.shape)\n",
        "    else:\n",
        "        img_data= np.expand_dims(img_data, axis=3)\n",
        "        #print (img_data.shape)\n",
        "\n",
        "else:\n",
        "    if K.common.image_dim_ordering()=='th':\n",
        "        img_data=np.rollaxis(img_data,3,1)\n",
        "        print (img_data.shape)\n",
        "\n",
        "\n",
        "        labels[0:722] = 0\n",
        "        labels[723:1823] = 1\n",
        "        labels[1824:3231] = 2\n",
        "        \n",
        "        \n",
        "        X_train.shape\n",
        "        \n",
        "\n",
        "        \n",
        "USE_SKLEARN_PREPROCESSING=False\n",
        "\n",
        "if USE_SKLEARN_PREPROCESSING:\n",
        "    # using sklearn for preprocessing\n",
        "    from sklearn import preprocessing\n",
        "\n",
        "    def image_to_feature_vector(image, size=(128, 128)):\n",
        "        # resize the image to a fixed size, then flatten the image into\n",
        "        # a list of raw pixel intensities\n",
        "        return cv2.resize(image, size).flatten()\n",
        "\n",
        "    img_data_list=[]\n",
        "    for dataset in data_dir_list:\n",
        "        img_list=os.listdir(data_path+'/'+ dataset)\n",
        "        print ('Loaded the images of dataset-'+'{}\\n'.format(dataset))\n",
        "        for img in img_list:\n",
        "            input_img=cv2.imread(data_path + '/'+ dataset + '/'+ img )\n",
        "            input_img=cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)\n",
        "            input_img_flatten=image_to_feature_vector(input_img,(128,128))\n",
        "            img_data_list.append(input_img_flatten)\n",
        "\n",
        "    img_data = np.array(img_data_list)\n",
        "    img_data = img_data.astype('float32')\n",
        "    #print (img_data.shape)\n",
        "    img_data_scaled = preprocessing.scale(img_data)\n",
        "    #print (img_data_scaled.shape)\n",
        "\n",
        "    if K.common.image_dim_ordering()=='th':\n",
        "        img_data_scaled=img_data_scaled.reshape(img_data.shape[0],num_channel,img_rows,img_cols)\n",
        "        print (img_data_scaled.shape)\n",
        "\n",
        "    else:\n",
        "        img_data_scaled=img_data_scaled.reshape(img_data.shape[0],img_rows,img_cols,num_channel)\n",
        "        print (img_data_scaled.shape)\n",
        "\n",
        "\n",
        "    if K.image_dim_ordering()=='th':\n",
        "        img_data_scaled=img_data_scaled.reshape(img_data.shape[0],num_channel,img_rows,img_cols)\n",
        "        print (img_data_scaled.shape)\n",
        "\n",
        "    else:\n",
        "        img_data_scaled=img_data_scaled.reshape(img_data.shape[0],img_rows,img_cols,num_channel)\n",
        "        print (img_data_scaled.shape)\n",
        "\n",
        "if USE_SKLEARN_PREPROCESSING:\n",
        "    img_data=img_data_scaled\n",
        "    \n",
        "    #%%\n",
        "labels[0:1000]\n",
        "#%%"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3231, 128, 128)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjqCL9IB9oGU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Assigning Labels\n",
        "\n",
        "# Define the number of classes\n",
        "num_classes = 3\n",
        "\n",
        "names = ['AMD','DME','NORMAL']\n",
        "\n",
        "# convert class labels to on-hot encoding\n",
        "Y = np_utils.to_categorical(labels, num_classes)\n",
        "\n",
        "#Shuffle the dataset with random state=2\n",
        "X,y = shuffle(img_data,Y, random_state=2)\n",
        "# Split the dataset with 20% testing data\n",
        "X_train, X_test, y_train, y_test =  train_test_split(X, y, test_size=0.20)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hl48bpZK9oGX",
        "colab_type": "text"
      },
      "source": [
        "# Define the model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfYoSnSz9oGY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 800
        },
        "outputId": "7dd0f9b8-ecd8-4e67-f47a-4d6b950ecf35"
      },
      "source": [
        "# Defining the model \n",
        "# Feel free to use CNNs/Dense Networks\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Convolution2D(256,nb_row=3, nb_col=3, activation='relu', input_shape=(128,128,1)))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "model.add(Convolution2D(128, nb_row=3, nb_col=3, activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "model.add(Convolution2D(64,nb_row=3, nb_col=3, activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "model.add(Convolution2D(32,nb_row=3, nb_col=3, activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "learning_rate = 0.001\n",
        "opt = adam(lr=learning_rate)\n",
        "model.compile(optimizer=opt,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Viewing model_configuration\n",
        "model.summary()\n",
        "#model.get_config()\n",
        "#model.layers[0].get_config()\n",
        "#model.layers[0].input_shape\n",
        "#model.layers[0].output_shape\n",
        "#model.layers[0].output\n",
        "#model.layers[0].get_weights()\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", input_shape=(128, 128,...)`\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 126, 126, 256)     2560      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 63, 63, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 61, 61, 128)       295040    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 30, 30, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 28, 28, 64)        73792     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 12, 12, 32)        18464     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 6, 6, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1152)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               295168    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 728,355\n",
            "Trainable params: 728,355\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsQM8ebQ9oGb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 800
        },
        "outputId": "9902d8cc-7370-4c04-eabe-53aed9cefcb8"
      },
      "source": [
        "# Train and fit wit appropiate batch size, epochs, verbose = 1 and validation set\n",
        "hist = model.fit(X_train, y_train, batch_size = 8, nb_epoch=20, verbose=1)\n",
        "\n",
        "# model saving \n",
        "from keras.models import model_from_json\n",
        "from keras.models import load_model\n",
        "\n",
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"model.h5\")\n",
        "print(\"Saved model to disk\")\n",
        "\n",
        "# load json and create model\n",
        "json_file = open('model.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"model.h5\")\n",
        "print(\"Loaded model from disk\")\n",
        "\n",
        "# Save the model in hdf5 file\n",
        "model.save('/content/gdrive/My Drive/Deep_Learning/Course/Project/saved_models/Oct_model.h5')\n",
        "\n",
        "# Load the saved model\n",
        "loaded_model= load_model('/content/gdrive/My Drive/Deep_Learning/Course/Project/saved_models/Oct_model.h5')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "2584/2584 [==============================] - 21s 8ms/step - loss: 0.5634 - accuracy: 0.7457\n",
            "Epoch 2/20\n",
            "2584/2584 [==============================] - 15s 6ms/step - loss: 0.1517 - accuracy: 0.9454\n",
            "Epoch 3/20\n",
            "2584/2584 [==============================] - 15s 6ms/step - loss: 0.0630 - accuracy: 0.9764\n",
            "Epoch 4/20\n",
            "2584/2584 [==============================] - 15s 6ms/step - loss: 0.1023 - accuracy: 0.9636\n",
            "Epoch 5/20\n",
            "2584/2584 [==============================] - 15s 6ms/step - loss: 0.0518 - accuracy: 0.9803\n",
            "Epoch 6/20\n",
            "2584/2584 [==============================] - 15s 6ms/step - loss: 0.0113 - accuracy: 0.9954\n",
            "Epoch 7/20\n",
            "2584/2584 [==============================] - 15s 6ms/step - loss: 0.0420 - accuracy: 0.9865\n",
            "Epoch 8/20\n",
            "2584/2584 [==============================] - 15s 6ms/step - loss: 0.0453 - accuracy: 0.9876\n",
            "Epoch 9/20\n",
            "2584/2584 [==============================] - 15s 6ms/step - loss: 0.0204 - accuracy: 0.9946\n",
            "Epoch 10/20\n",
            "2584/2584 [==============================] - 15s 6ms/step - loss: 0.0388 - accuracy: 0.9857\n",
            "Epoch 11/20\n",
            "2584/2584 [==============================] - 15s 6ms/step - loss: 2.0980e-04 - accuracy: 1.0000\n",
            "Epoch 12/20\n",
            "2584/2584 [==============================] - 15s 6ms/step - loss: 4.7490e-05 - accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "2584/2584 [==============================] - 15s 6ms/step - loss: 3.0280e-05 - accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "2584/2584 [==============================] - 15s 6ms/step - loss: 2.1271e-05 - accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "2584/2584 [==============================] - 15s 6ms/step - loss: 1.5634e-05 - accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "2584/2584 [==============================] - 15s 6ms/step - loss: 1.1741e-05 - accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "2584/2584 [==============================] - 15s 6ms/step - loss: 9.0268e-06 - accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "2584/2584 [==============================] - 15s 6ms/step - loss: 7.0302e-06 - accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "2584/2584 [==============================] - 15s 6ms/step - loss: 5.5327e-06 - accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "2584/2584 [==============================] - 15s 6ms/step - loss: 4.4081e-06 - accuracy: 1.0000\n",
            "Saved model to disk\n",
            "Loaded model from disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4m4i34pV9oGe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "37a2fd8c-c437-4061-f644-83d2c761e545"
      },
      "source": [
        "# Evaluate the model w.r.t Test Loss and Test Accuracy\n",
        "score = model.evaluate(X_test,y_test)\n",
        "print('Test Loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "647/647 [==============================] - 2s 3ms/step\n",
            "Test Loss: 2.1549673768798332e-05\n",
            "Test accuracy: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wX8dtMTp9oGh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 814
        },
        "outputId": "dec8fe24-693e-4962-e2e2-5e4d75e415c9"
      },
      "source": [
        "# Predict model on Test Data\n",
        "\n",
        "Y_pred = model.predict(X_test)\n",
        "print(Y_pred)\n",
        "\n",
        "# Printing the confusion matrix\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "import itertools\n",
        "\n",
        "# Print the classes of the Prediction\n",
        "y_pred = model.predict_classes(X_test)\n",
        "print(y_pred)\n",
        "\n",
        "target_names = ['AMD', 'DME', 'Normal']\n",
        "                                        \n",
        "# Plotting the confusion matrix\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "#Computation  confusion matrix\n",
        "cnf_matrix = (confusion_matrix(np.argmax(y_test,axis=1), y_pred))\n",
        "\n",
        "np.set_printoptions(precision=3)\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "# Plotting non-normalized confusion matrix\n",
        "plot_confusion_matrix(cnf_matrix, classes=target_names,\n",
        "                      title='Confusion matrix')\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3.0855734e-19 1.0000000e+00 1.1370117e-21]\n",
            " [6.7806103e-21 1.0000000e+00 8.5730831e-24]\n",
            " [4.4346526e-21 1.6590982e-17 1.0000000e+00]\n",
            " ...\n",
            " [8.0356415e-08 9.9999988e-01 6.2162421e-11]\n",
            " [5.6037019e-10 1.3019333e-09 1.0000000e+00]\n",
            " [3.8303654e-07 4.8803746e-11 9.9999964e-01]]\n",
            "[1 1 2 1 2 1 0 0 0 1 0 2 1 2 2 2 1 2 0 2 0 2 2 2 0 2 1 0 1 2 2 2 0 2 2 0 0\n",
            " 0 0 0 0 2 1 2 0 2 0 0 0 2 1 1 0 1 1 1 0 1 2 2 2 1 0 2 1 0 0 1 1 1 2 0 0 2\n",
            " 2 1 2 2 1 2 0 2 2 2 0 0 2 0 1 1 2 2 2 2 0 2 1 1 2 1 2 2 0 2 1 1 2 2 0 0 2\n",
            " 1 2 1 2 2 2 1 1 2 2 1 1 2 0 2 2 0 1 2 0 1 2 2 2 2 0 2 2 1 2 0 1 1 1 1 0 2\n",
            " 2 1 0 2 1 1 0 1 1 2 2 2 1 1 1 1 2 2 1 0 1 0 1 1 1 2 1 0 1 0 1 0 2 1 1 2 2\n",
            " 1 2 1 1 1 1 0 2 2 1 2 2 1 1 1 2 2 0 2 1 1 1 2 2 0 0 0 1 2 0 1 2 1 0 2 2 1\n",
            " 2 2 2 1 2 1 1 0 1 2 2 2 2 0 2 1 1 0 2 0 2 1 1 1 1 2 2 2 1 2 2 2 1 2 2 2 1\n",
            " 1 2 2 0 1 2 2 2 2 1 2 1 1 2 0 2 1 2 0 1 0 1 0 0 2 1 0 0 1 2 2 0 0 2 1 0 0\n",
            " 0 2 1 1 1 2 1 1 2 1 2 2 1 2 2 2 2 2 2 1 1 2 2 1 2 1 0 0 2 2 2 1 2 2 1 1 2\n",
            " 0 0 2 2 2 1 2 2 2 2 1 0 2 2 2 2 1 0 1 1 2 2 2 1 1 2 1 2 2 1 2 1 1 2 1 2 2\n",
            " 1 0 1 2 2 2 2 0 2 1 1 1 2 1 0 2 2 1 2 2 2 0 0 0 0 2 2 1 0 2 1 0 1 1 2 1 2\n",
            " 2 2 1 0 2 2 2 1 2 1 0 2 1 2 1 1 2 1 2 1 0 1 0 2 2 2 1 2 1 1 0 1 2 2 1 2 2\n",
            " 2 2 2 2 1 0 1 1 1 0 0 1 0 2 1 2 1 0 1 2 2 2 0 1 2 2 1 2 1 2 1 2 0 1 2 1 1\n",
            " 1 1 2 0 2 2 2 2 2 2 2 0 2 2 1 0 2 1 0 1 1 2 1 0 1 1 1 0 1 2 0 1 1 1 1 2 1\n",
            " 2 0 2 0 0 2 2 0 2 0 2 2 0 2 2 2 1 1 1 1 1 2 0 2 2 1 2 2 0 2 1 1 1 1 1 2 1\n",
            " 2 1 1 0 2 2 0 1 0 1 1 1 2 1 2 2 1 2 2 1 0 0 0 2 2 2 2 2 1 2 1 0 0 1 2 2 2\n",
            " 0 2 2 2 0 0 2 1 2 1 1 1 2 2 1 0 0 0 1 2 0 1 2 1 1 2 2 2 2 2 2 1 1 0 2 1 0\n",
            " 1 1 1 0 2 2 0 2 0 2 0 2 1 2 2 1 2 2]\n",
            "Confusion matrix, without normalization\n",
            "[[134   0   0]\n",
            " [  0 226   0]\n",
            " [  0   0 287]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}